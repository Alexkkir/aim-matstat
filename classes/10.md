$$
\newcommand{\horline}{\noindent\rule{\textwidth}{0.4pt}}
\renewcommand{\line}{\\ \hline}

\newcommand{\N}{{\mathbb{N}}}
\newcommand{\Z}{{\mathbb{Z}}}
\newcommand{\Q}{{\mathbb{Q}}}
\newcommand{\R}{{\mathbb{R}}}
\renewcommand{\C}{{\mathbb{C}}}
\renewcommand{\P}{{\mathbb{P}}}
\newcommand{\F}{{\mathbb{F}}}
\newcommand{\PP}{\text{П}}
\newcommand{\E}{{\mathbb{E}}}
\newcommand{\D}{{\mathbb{D}}}
\newcommand{\I}{{\mathbb{I}}}

\newcommand{\Pp}{\mathcal{P}}
\newcommand{\Oo}{\mathcal{O}}
\newcommand{\Hh}{\mathcal{H}}
\newcommand{\Aa}{\mathcal{A}}
\newcommand{\Cc}{\mathcal{C}}
\newcommand{\Xx}{\mathcal{X}}

\renewcommand{\O}{{\Omega}}
\newcommand{\G}{{\Gamma}}
\renewcommand{\a}{{\alpha}}
\renewcommand{\b}{{\beta}}
\newcommand{\g}{{\gamma}}
\renewcommand{\d}{{\delta}}
\newcommand{\e}{{\varepsilon}}
\renewcommand{\f}{{\varphi}}
\newcommand{\s}{{\sigma}}
\newcommand{\w}{{\omega}}
\renewcommand{\r}{{\rho}}
\renewcommand{\l}{{\lambda}}
\renewcommand{\k}{{\kappa}}
\renewcommand{\L}{{\Lambda}}
\renewcommand{\t}{{\theta}}

\newcommand{\red}[1]{{\color{red} #1}}
\newcommand{\blue}[1]{{\color{blue} #1}}
\newcommand{\green}[1]{{\color{green} #1}}
\newcommand{\purple}[1]{{\color{purple} #1}}
\newcommand{\orange}[1]{{\color{orange} #1}}
\renewcommand{\bold}[1]{\textbf{#1}}
\renewcommand{\vec}[1]{{\overrightarrow{#1}}}
% \renewcommand{\inf}{{\infty}}

% \newenvironment{eqn}{ \begin{align} \begin{split} }{ \end{split} \end{align} }

% \newenvironment{eq}{\begin{align*}}{\end{align*}}

\newcommand{\arr}[1]{{\left[ \begin{array}{*{20}{>{\centering\arraybackslash}c}} #1 \end{array} \right]}}


\renewcommand{\table}[3]{\begin{center}\begin{tabular}{|*{#1}{>{\centering\arraybackslash}p{#2\textwidth}|}} \hline #3 \hline \end{tabular}\end{center}}

\newcommand{\tablea}[2]{\begin{center}\begin{tabular}{|*{#1}{>{\centering\arraybackslash}c|}} \hline #2 \hline \end{tabular}\end{center}}
  

% \forall \e > 0 \ \exists \d > 0 : \ \forall x \in O_\delta(x_0) \

\renewcommand{\leadsto}{{\ \Longrightarrow \ }}
\newcommand{\sat}{{\mapsto}}
\newcommand{\means}{{\Rightarrow}}
\newcommand{\hence}{{\ \Rightarrow \ }}
\newcommand{\thesame}{{\ \Leftrightarrow \ }}
\newcommand{\<}{\leqslant}
\renewcommand{\>}{\geqslant}
% \let\oldline\|
% \renewcommand{\#}{\oldline}
% \renewcommand{\|}{\Big|}
\renewcommand{\=}{\equiv}
\newcommand{\9}{\Big(}
\newcommand{\0}{\Big)}
\newcommand{\calc}[2]{\Bigg|_{#1}^{#2}}
\newcommand{\dx}{\, dx}
\newcommand{\dt}{\, dt}
\newcommand{\dy}{\, dy}
\newcommand{\dz}{\, dz}
\newcommand{\du}{\, du}
\newcommand{\dv}{\, dv}
\newcommand{\df}{\, d \f}
\newcommand{\bs}{\Big[}
\newcommand{\be}{\Big]}
\renewcommand{\for}{\ | \ }

\renewcommand{\Im}{{\operatorname{Im}}}
\renewcommand{\Re}{{\operatorname{Re}}}
\newcommand{\im}{{\operatorname{Im}}}
\newcommand{\re}{{\operatorname{Re}}}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\con}{\operatorname{con}}
\newcommand{\tr}{\operatorname{tr}}
\newcommand{\trace}{\operatorname{trace}}
\newcommand{\sign}{\operatorname{sign}}
\newcommand{\dom}{\operatorname{dom}}
\newcommand{\ifff}{\operatorname{iff}}
\newcommand{\st}{\operatorname{s.t.}}
\newcommand{\diag}{\operatorname{diag}}
\newcommand{\prox}{\operatorname{prox}}
\newcommand{\proj}{\operatorname{proj}}
\newcommand{\const}{\operatorname{const}}
\newcommand{\span}{\operatorname{span}}
\newcommand{\var}{\operatorname{Var}}
\newcommand{\argmin}{\operatorname{argmin} \limits}
\newcommand{\argmax}{\operatorname{argmax} \limits}
\newcommand{\cov}{\operatorname{cov}}


\newcommand{\iid}{\text{i.i.d.}}
\newcommand{\else}{\text{else}}

\renewcommand{\exp}[1]{\operatorname{exp} \{ #1 \}}
\newcommand{\eexp}[1]{\operatorname{exp} \Big \{ #1 \Big \}}
\renewcommand{\eq}{= \\ =}
\newcommand{\shift}[1]{\Big\{ #1 \Big\}}
\newcommand{\set}[1]{\{ #1 \}}
\newcommand{\sset}[1]{\Big \{ #1 \Big \}}
\newcommand{\scalar}[1]{\langle #1 \rangle}
$$

# Занятие 10. Регрессия (продолжение)

### Вспоминаем предыдущее занятие

Данные:
$$
(\bar x_1, y_1), \dots, (\bar x_n, y_n)
$$
Нужно уметь предсказывать $y$ по $x$.

Есть разные подходы:

* параметрические

  * линейная регрессия: $y = \bar y^\top \bar x + \e$

    <img src="/home/alexkkir/AIM/matstat/classes/assets/image-20230423230446264.png" alt="image-20230423230446264" style="zoom:67%;" />

  * обобщенные линейные модели: есть экспоненциальное семейство $p(x, v)$. Предсказываем как $y_i \sim p(x, \bar \b^\top \bar x)$.

* непараметрические

  * Nadaraya-Watson (kernel regression)
  * регресионная (histogramm)
  * super smooth 
  * LOESS
  * wavelets

Сегодня обсудим последние 4 пункта

# Пара слов про параметрическую регрессию

### Гребневая регрессия

Если некоторые столбцы матрицы $X$ линейно зависимы, то матрица $X^\top X$ будет необратима (или обратная к ней будет очень большой), а результат предсказания будет очень неустойчивым.

![image-20230423232218532](/home/alexkkir/AIM/matstat/classes/assets/image-20230423232218532.png)

Решение:

![image-20230423232620254](/home/alexkkir/AIM/matstat/classes/assets/image-20230423232620254.png)

Смысл: уменьшаем число обусловленности

![image-20230423232805105](/home/alexkkir/AIM/matstat/classes/assets/image-20230423232805105.png)

То есть
$$
\mu(A) = {\l_{\max} \over \l_\min} \mapsto {\l_\max + \l \over \l_\min + \l} = \mu(A + \l I)
$$
Это делает матрицу обратимой.

### MSE в задаче регрессии

$$
\text{MSE} (\hat a) =\E[(\hat a - a)^2] = (\text{bias}(\hat a))^2 + \var \hat a = (\E \hat a - a)^2 + \var \hat a
$$

Для линейной регрессии имеем:

![image-20230423233318136](/home/alexkkir/AIM/matstat/classes/assets/image-20230423233318136.png)

Теорема Гаусса-Маркова. Пусть $\E \e_i = 0, \ \var \e_i = \s^2, \cov(\e_i, \e_j) = 0$ (то есть допустимо, что $\e \not \sim N(0, \s^2)$). Тогда

1. $\hat a = x_0^T  (x^\top x)^{-1} x^\top y$ является несмещенной оценкой для $a = x_0^\top \b$

2. Для любой другой несмещенной оценки дисперсия будет больше:
   $$
   \forall \hat a^*: \E[\hat a^*] = a \quad \var(\hat a^*) \> \var (\hat a)
   $$
   

# Непараметрическая регрессия

### Регрессограмма

Значения регрессионной зависимости в близких точках должны быть примерно одинаковы

<img src="/home/alexkkir/AIM/matstat/classes/assets/image-20230423234413881.png" alt="image-20230423234413881" style="zoom:70%;" />

Linear smoother: $\hat{ \bar{y} }= L \cdot \bar{y}$. В случае регрессограммы:

<img src="/home/alexkkir/AIM/matstat/classes/assets/image-20230423234750795.png" alt="image-20230423234750795" style="zoom:80%;" />

Effective degree of freedom:

![image-20230423234841847](/home/alexkkir/AIM/matstat/classes/assets/image-20230423234841847.png)

* в случае линейной регрессии равно количеству переменных
* в случае регрессограммы равно количеству блоков

### Supersmu

Super smoother – Friedman, 1984

Философия: любая хорошая функция является локально линейной

<img src="/home/alexkkir/AIM/matstat/classes/assets/image-20230423235247593.png" alt="image-20230423235247593" style="zoom:80%;" />

Как выбирается $S$? Тут используется очень рандомный способ, но в целом рабочий. Множество $S$ состоит из 3 чисел:

![image-20230423235456943](/home/alexkkir/AIM/matstat/classes/assets/image-20230423235456943.png)

### LOESS

![image-20230424000009631](/home/alexkkir/AIM/matstat/classes/assets/image-20230424000009631.png)

Похоже на supersmu, но есть два отличия:

1. Добавляем каждому объекту вес
2. Пересчитываем вес на основании ошибки

![image-20230424000235312](/home/alexkkir/AIM/matstat/classes/assets/image-20230424000235312.png)

Довольно похоже на AdaBoost

### Wavelets

Напоминание:
$$
L^2[a, b] = \set{f: \ \int_a^bf^2(x)\dx < \infty}
$$
В этом пространстве существует скалярное произведение:
$$
\langle f, g \rangle = \int_a^b f(x) g(x) \dx
$$
Также тут есть бесконечномерный базис
$$
\f_1, \dots, \f_n \in L^2[a, b] 
$$
для которого выполняется:

1. $\langle \f_i, \f_j \rangle = \d_{ij} $ (ортонормированность)
2. $\forall i \ \langle f, \f_i \rangle = 0 \hence f \equiv 0  $ (полная система)

Таким образом, любую функцию можно разложить по базису:
$$
\forall f \in L^2[a, b]: \quad f(x) = \sum \a_i \f_i(x), \ \a_i = \langle f, \f_i \rangle
$$
Известные базисы:

* полиномы Эрмита
* полиномы Лежандра
* базис Хаара (Haar basis)

#### Haar basis

Пусть $[a, b] = [0, 1]$. Пусть
$$
\begin{align*}
\f(x) &\equiv 1 - \text{father wavelet} \\
\psi(x) &= \begin{cases} -1, & x \in [0, 1/2] \\ 1, & x \in (1/2, 1] \end{cases} - \text{mother wavelet} \\
\psi_{jk}(x) &= 2^{jk} \psi(2^jx + k), \quad j = 1, 2, \dots, \quad k = 0, 1, \dots 2^j - 1
\end{align*}
$$
Графики:

<img src="/home/alexkkir/AIM/matstat/classes/assets/image-20230424142745071.png" alt="image-20230424142745071" style="zoom:67%;" />

Разложим теперь функцию $f$ по построенному базису:
$$
f(x) = \a + \sum_{j = 0}^\infty \sum_{k = 0}^{2^j - 1} \b_{jk} \psi_{jk}(x), \quad \a = \int_{0}^1  f(x) \f(x) \dx, \quad \b_{jk} = \int_{0}^1 f(x) \psi_{jk}(x) \dx
$$

#### Применение к регрессии

$$
y_i = f(x_i) + \e_i, \quad \e_i \sim N(0, \s^2), \quad f \in L^2[0, 1]
$$

Оцениваем коэффициенты $f$ в разложении по базису, предварительно обрубив ряд:
$$
\hat f(x) = \hat \a + \sum_{j = -}^J \sum_{k = 0}^{2^j - 1}\hat \b_{jk} \psi_{jk} (x), \quad \hat \a = {1 \over n} \sum_{i = 1}^n y_i, \quad \hat \b_{jk} = {1 \over n} \sum_{i = 1}^n y_i \psi_{jk} (x_i)
$$

#### При чем здесь нормальное распределение?

$$
y_i \sim N(f(x_i), \s^2) \\
\hence \hat \a \sim N \9 \underbrace{{1 \over n} \sum_{i = 1}^n f(x_i) \f(x_i)}_{\to \int_0^1 f(x) \f(x) \dx}, \underbrace{{1 \over n^2} \sum \f^2 (x_i) \s^2}_{\approx {1 \over n} \int_0^1 \f^2 (x) \dx \s^2 \to 0} \0
$$

Значит, при $n \to \infty$ наша оценка стремится к правильному значению

# Сравнение регрессионных моделей

### Generalized cross-validation (GCV)

Модель: $y_i = r(x_i) + \e_i$. Используем метод leave-one-out и строим $r_{(-i)}$. Можно перебрать все точки и получить общую ошибку $\sum (y_i - r_{(-i)}(x_i))^2$, но это долго. Вместо этого пользуются утверждением:

**Утверждение.**
$$
y_i - r_{(-i)}(x) = {y_i - r(x_i) \over 1 - l_{ii}}
$$
где $l_{ii}$ это $i$-ый диагональный элемент матрицы $L = X(X^\top X)^{-1} X^\top$. Это нетривиальное утверждение (доказательство см. в блоге Roy Hyndman)

Тогда для *любого* линейного сглаживателя $r$ (то есть $\hat y = L y $) мы можем посчитать ошибку по формуле выше. В языке R используется несколько аппроксимаций:
$$
\sum (y_i - r_{(-i)}(x_i))^2 = \sum_{i = 1}^n \9 {y_i - r(x_i) \over 1 - l_{ii}} \0 \approx \shift{l_{11} + l_{nn} = \tr L \hence l_{ii} = \tr L / n} \approx {\sum (y_i - r(x_i)) \over (1 - {\tr L / n})^2} \approx (1 + 2 \tr L / n) \sum (y_i - r(x_i))^2
$$

### Критерий Акаике

Тема из раздела model misspecification. У нас опять есть регрессионная модель: $y_i = r(x_i) + \e_i$. Будем предполагать, что $r(x_i) = \scalar{x_i, \b}, \ \e_i \sim N(0, \s^2)$. Считаем, что данные устроены как раз таким образом. 

Теперь у нас есть модель-кандидат $\hat r$. С помощью KL-divergence можно измерить, насколько она близка к настоящей, посмотрев на распределение предсказаний:
$$
KL(p_{true}, p_{cand}) = ?, \quad p_{true} = x \bar \b + \bar e \sim N(x \bar \b, \s^2 I), \quad p_{cand} \sim N(x \hat \b, \hat \s^2 I)
$$
Тогда
$$
KL(p_{true}, p_{cand}) = n \log \hat \s^2 + {n \s^2 \over \hat \s^2} + {1 \over \s^2} (\mu - \hat \mu)^\top (\mu - \hat \mu) + R(\mu, \s^2), \quad \mu = x \bar \b
$$
Однако мы не знаем $\mu, \sigma$. Что делать? Возьмем матожидание для 2 и 3 слагаемого. Можно доказать, что 
$$
{n \s^2 \over \hat \s^2} \sim \Xx_{n - m}^2, 
\quad {1 \over \s^2} (\mu - \hat \mu)^\top (\mu - \hat \mu) \sim F_{n, n - m}
$$
Значит, 
$$
\E [{n \s^2 \over \hat \s^2} ]= n - m, \quad \E [ {1 \over \s^2} (\mu - \hat \mu)^\top (\mu - \hat \mu)] = {nm \over n - m - 2}
$$
В итоге получаем
$$
L(p_{true}, p_{cand}) = n \log \9 {1 \over n}  \sum_{i = 1}^n (\hat y_i - y_i)^2 \0 + 1 + {2 (m + 1) \over n + m - 2} \to \min
$$
Но что здесь $m$? Так же, как в случае GCV, заменим $m \mapsto \tr L$. Так можно сделать, ведь
$$
\hat y = \underbrace{X(X^\top X)^{-1} X^\top}_{L} y, \quad \tr L = \tr (X^\top X)^{-1} (X^\top X) = \tr I = m
$$

# Анализ выживаемости

Теперь переходим к современным прикладным методам. 

Анализ данных о моментах времени с некоторого определенного момента до наступления события. Особенности:

1. Есть цензурируемые наблюдения (отсутствует часть информации)
2. Несимметричные распределения ($\means$ у них тяжелые хвосты)

### Пример

Пациент сделал операцию от раке. После операции он ходит к доктору раз в несколько месяцев. Нам интересно, когда у него снова появятся симптомы болезни (рецидив). Основная проблема: пациент может перестать ходить к врачу (переезд в другой город / погиб в автокатосторфе / что-то еще). Из-за этого у нас неполные данные

### Survival & hazard function

Survival funciton. Пусть $T$ - время жизни пациента
$$ {t}
s(T) = 1 - F_T(t) = 1 - \P \set{T \< t} = \P \set{T > t}
$$
Hazard function (aka instance death rate):
$$
h(t) = \lim_{\Delta t \to 0} {\P \set{t \< T \< t + \Delta t \for T \> t} \over \Delta t}
$$
**Утверждение**

1. $h(t) = p(t) / s(t)$

2. $h(t) = -(\log s(t))'$

*Доказательство*

<img src="/home/alexkkir/AIM/matstat/classes/assets/image-20230424154506055.png" alt="image-20230424154506055" style="zoom:67%;" />

Как оценить $h(t)$ и $s(t)$? Как использовать цензурируемые наблюдения?

### Оценивание survival function

#### Банальный метод

$$
s(t) = 1 - F(t) \hence \hat s(t) = 1 - {1 \over n} \sum_{i = 1}^n \I[T_i \< t] = {\# \set{T > t} \over n}
$$

Это плохой метод, т.к. мы не используем цензурируемые наблюдения

#### Хороший метод

Разобьем временную шкалу на бины и для каждого бина буем считать

* $n_i$ - количество живых
* $d_i$ - количество мертвых
* $c_i$ - количество цензурируемых (которые последний раз встречались на этом интервале)

<img src="/home/alexkkir/AIM/matstat/classes/assets/image-20230424155015669.png" alt="image-20230424155015669" style="zoom:67%;" />

Пусть $n_j' = n_j - c_j / 2 $. Утверждается, что хорошей оценкой $s$ будет
$$
\hat s(t) = \prod_{j = 1}^k (1 - {d_j \over n_j'})
$$
Почему?
$$
s(t_k) = \P \set{T > t_k} = \P \set{T > t_k \for T > t_{k - 1}} \P \set{T > t_{k - 1}} = \dots 
= \prod_{j = 1}^k \underbrace{\P \set{T > t_j \for T > t_{j - 1}}}_{\approx 1 - d_j / n_j'} \cdot \underbrace{\P \set{T > t_0}}_{=1}
$$
У этого метода есть недостаток: при больших $c_j$ у нас может возникнуть отрицательное число



